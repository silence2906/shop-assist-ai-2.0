{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90bb1e2a",
   "metadata": {
    "id": "90bb1e2a"
   },
   "source": [
    "# ShopAssist AI 2.0Upgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1cc72",
   "metadata": {
    "id": "5bf1cc72"
   },
   "source": [
    "## Part 1: Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eTECjBM1_t1B",
   "metadata": {
    "id": "eTECjBM1_t1B"
   },
   "source": [
    "\n",
    "#### Project Background\n",
    "\n",
    "In today's digital age, online shopping has become the go-to option for many consumers. However, the overwhelming number of choices and the lack of personalized assistance can make the shopping experience daunting. To address this, we have developed **ShopAssist AI, a chatbot that combines the power of large language models and rule-based functions to ensure accurate and reliable information delivery**.\n",
    "\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "*Given a dataset containing information about laptops (product names, specifications, descriptions, etc.), build a chatbot that parses the dataset and provides accurate laptop recommendations based on user requirements*.\n",
    "\n",
    "\n",
    "You can load the data and see it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "l7BLDeM5MXrC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15904,
     "status": "ok",
     "timestamp": 1730457983582,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "l7BLDeM5MXrC",
    "outputId": "81c81f2a-fd59-44f1-8aa4-f12e75185a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/387.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m378.9/387.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.1/387.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install OpenAI library\n",
    "!pip install -U -q openai tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "VnAN5gPkCAfl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44998,
     "status": "ok",
     "timestamp": 1730458036121,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "VnAN5gPkCAfl",
    "outputId": "d7c8a3ec-e452-48d1-a691-92dce01c7e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "PUU30mtJI5qr",
   "metadata": {
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1730458040408,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "PUU30mtJI5qr"
   },
   "outputs": [],
   "source": [
    "# Import other libraries\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.width',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sO9hp14II8GP",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730458042486,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "sO9hp14II8GP"
   },
   "outputs": [],
   "source": [
    "filepath = '/content/drive/MyDrive/GenAI/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc7e3b",
   "metadata": {
    "id": "81bc7e3b"
   },
   "source": [
    "#### Approach:\n",
    "\n",
    "1. **Conversation and Information Gathering**: The chatbot will utilize language models to understand and generate natural responses. Through a conversational flow, it will ask relevant questions to gather information about the user's requirements.\n",
    "2. **Information Extraction**: Once the essential information is collected, rule-based functions come into play, extracting top 3 laptops that best matches the user's needs.\n",
    "3. **Personalized Recommendation**: Leveraging this extracted information, the chatbot engages in further dialogue with the user, efficiently addressing their queries and aiding them in finding the perfect laptop solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7aada9",
   "metadata": {
    "id": "5e7aada9"
   },
   "source": [
    "## Part 2: System Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43fb33e",
   "metadata": {
    "id": "a43fb33e"
   },
   "source": [
    "\n",
    "#### Dataset\n",
    "\n",
    "We have a dataset `laptop.csv` where  each row describes the features of a single laptop and also has a small description at the end. The chatbot that we build will leverage LLMs to parse this `Description` column and provide recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b846d2",
   "metadata": {
    "id": "f5b846d2"
   },
   "source": [
    "#### Workings of the Chatbot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d39aba",
   "metadata": {
    "id": "73d39aba"
   },
   "source": [
    "The chatbot should ask a series of questions to\n",
    "- Determine the user's requirments. For simplicity, we have used 6 features to encapsulate the user's needs. The 6 features are as follows:\n",
    "    - GPU intensity\n",
    "    - Display quality\n",
    "    - Portability\n",
    "    - Multitasking\n",
    "    - Processing speed\n",
    "    - Budget\n",
    "\n",
    "- Confirm if the user's requirements have been correctly captured at the end.\n",
    "\n",
    "After that the chatbot lists down the top 3 products that are the most relevant, and engages in further conversation to help the user find the best one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H7d5QKmWLMyt",
   "metadata": {
    "id": "H7d5QKmWLMyt"
   },
   "source": [
    "# ShopAssist 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ca223",
   "metadata": {
    "id": "281ca223"
   },
   "source": [
    "#### Building the Chatbot\n",
    "\n",
    "Below is the system design for the chatbot for **ShopAssist 1.0**.\n",
    "\n",
    "![Chatbot_sys_design.png](https://drive.google.com/uc?id=1j-mw_dNcbxGcelQ0PmkDB0nKOpauU1wX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b581e9",
   "metadata": {
    "id": "51b581e9"
   },
   "source": [
    "|`Stage 1`\n",
    "\n",
    "- Intent Clarity Layer\n",
    "- Intent Confirmation Layer\n",
    "\n",
    "`Stage 2`\n",
    "\n",
    "- Product Mapping Layer\n",
    "- Product Information Extraction Layer\n",
    "\n",
    "`Stage 3`\n",
    "\n",
    "- Product Recommendation Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbceebf1",
   "metadata": {
    "id": "bbceebf1"
   },
   "source": [
    "##### Major functions behind the Chatbot\n",
    "\n",
    "Let's now look at a brief overview of the major functions that form the chatbot. We'll take a deep dive later\n",
    "\n",
    "\n",
    "\n",
    "- `initialize_conversation()`: This initializes the variable conversation with the system message.\n",
    "- `get_chat_completions()`: This takes the ongoing conversation as the input and returns the response by the assistant\n",
    "- `moderation_check()`: This checks if the user's or the assistant's message is inappropriate. If any of these is inappropriate, it ends the conversation.\n",
    "- `intent_confirmation_layer()`: This function takes the assistant's response and evaluates if the chatbot has captured the user's profile clearly. Specifically, this checks if the following properties for the user has been captured or not GPU intensity, Display quality, Portability, Multitasking, Processing speed, Budget\n",
    "- `dictionary_present()`: This function checks if the final understanding of user's profile is returned by the chatbot as a python dictionary or not. If there is a dictionary, it extracts the information as a Python dictionary.\n",
    "- `compare_laptops_with_user()`: This function compares the user's profile with the different laptops and come back with the top 3 recommendations.\n",
    "- `initialize_conv_reco()`: Initializes the recommendations conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd07e7a",
   "metadata": {
    "id": "8cd07e7a"
   },
   "source": [
    "In the next sections, we will look at how to write the code for the above functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JucmHnXYLHN3",
   "metadata": {
    "id": "JucmHnXYLHN3"
   },
   "source": [
    "# ShopAssist 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_jgTtyubKpJs",
   "metadata": {
    "id": "_jgTtyubKpJs"
   },
   "source": [
    "But in development of **ShopAssist2.0** , we leverage from Function Calling feature for improved performance and simple architecture.\n",
    "\n",
    "The architecture looks as shown below:\n",
    "\n",
    "|`Stage 1`\n",
    "\n",
    "- Intent Clarity Layer\n",
    "\n",
    "`Stage 2`\n",
    "\n",
    "- Product Mapping Layer\n",
    "\n",
    "`Stage 3`\n",
    "\n",
    "- Product Recommendation Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AEHPLlweMWq7",
   "metadata": {
    "id": "AEHPLlweMWq7"
   },
   "source": [
    "The following layers from ShopAssist 1.0 **are removed** as their purpose are filled by now using function calling in OpenAI API.\n",
    "\n",
    "1. intent_confirmation_layer()\n",
    "2. dictionary_present()\n",
    "3. initialize_conv_reco()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd717d",
   "metadata": {
    "id": "59bd717d"
   },
   "source": [
    "## Part 3: Technical Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mPMUbPd0R8nl",
   "metadata": {
    "id": "mPMUbPd0R8nl"
   },
   "source": [
    "## Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b636d",
   "metadata": {
    "id": "680b636d"
   },
   "source": [
    "### 3.1 - Import the libraries\n",
    "\n",
    "Let's start by importing the libraries that we'll require for this project. Following are the ones:\n",
    "- openai\n",
    "- pandas\n",
    "- os, json, ast\n",
    "\n",
    "Make sure the api key is stored in the text file `OPENAI_API_Key.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e05f4f",
   "metadata": {
    "executionInfo": {
     "elapsed": 2328,
     "status": "ok",
     "timestamp": 1730458061000,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "65e05f4f"
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import os, json, ast\n",
    "import openai\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c90af6c",
   "metadata": {
    "executionInfo": {
     "elapsed": 1942,
     "status": "ok",
     "timestamp": 1730458064430,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "7c90af6c"
   },
   "outputs": [],
   "source": [
    "# Read the OpenAI API key\n",
    "with open(filepath + \"OpenAI_API_Key.txt\",\"r\") as f:\n",
    "  openai.api_key = ' '.join(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6597837",
   "metadata": {
    "id": "f6597837"
   },
   "source": [
    "### 3.2 - Implementing Intent Clarity Layer\n",
    "\n",
    "\n",
    "- `initialize_conversation()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muGgwBrxxr58",
   "metadata": {
    "id": "muGgwBrxxr58"
   },
   "source": [
    "### `initialize_conversation()`:\n",
    "This initializes the variable conversation with the system message. Using prompt engineering and chain of thought reasoning, the function will enable the chatbot to keep asking questions until the user requirements have been captured in a dictionary. It also includes Few Shot Prompting(sample conversation between the user and assistant) to align the model about user and assistant responses at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "j2mgO9-Bdl5M",
   "metadata": {
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1730461517213,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "j2mgO9-Bdl5M"
   },
   "outputs": [],
   "source": [
    "# initialize_conversation function\n",
    "def initialize_conversation():\n",
    "  '''\n",
    "  Returns a list [{'role':'system','content': system_message}]\n",
    "  '''\n",
    "  delimiter = '####'\n",
    "\n",
    "\n",
    "  system_message = f'''\n",
    "  You are very intelligent laptop gadget expert and your goal is to find out best laptop for a user for given input.\n",
    "  You need to ask relevant questions to the user and understand the user profile  by analysing the user's responses.\n",
    "  Your final objective is to get following parameters from user's conversation. The parameters are 'GPU intensity','Display quality','Portability','Multitasking','Processing speed'and'Budget', and be confident of the values.\n",
    "  You need to ask probing questions to the user in case any of these parameters are not obtained from user's interaction.\n",
    "  The value for the 'Budget' should be numerical value extracted from user's response.\n",
    "  The value of all keys except 'Budget' should be either 'high' or 'medium' or 'low' based on the importance of the corresponding keys as stated by user.\n",
    "  All the values in the example dictionary are only representative values.\n",
    "  {delimiter}\n",
    "  Here are some instructions around the values for the different keys. if you do not follow this, you will be heavily penalized.\n",
    "  - The value of all keys except 'Budget' should be strictly either 'high' or 'medium' or 'low' based on the importance of the corresponding keys as stated by user.\n",
    "  - The value for the 'Budget' should be numerical value extracted from user's response.\n",
    "  - 'Budget' value needs to be greater than or equal to 25000 INR. If the user says less than that, please mention to user that there are no laptops in that range.\n",
    "  - Please do not randomly assign any value to the parameters.\n",
    "  - The value needs to be inferred from the user's response.\n",
    "  - Please ask one question at a time to capture values for the parameters.\n",
    "  {delimiter}\n",
    "\n",
    "  Once you have obtained all the parameter, your goal is to extract details of the top 3 laptops matching to the parameters obtaned earlier in the user's conversation .\n",
    "  And this you will do by function calling with compare_laptops_with_user function.\n",
    "\n",
    "  {delimiter}\n",
    "    Once you get the list of top 3 laptops you will need to present the details in the personlized format it and show the recomendations to the\n",
    "    user in the following format:\n",
    "    1. <Laptop name>: <Basic laptop specs in brief>, <price of laptop>\n",
    "    2. <Laptop name>: <Basic laptop specs in brief>, <price of laptop>\n",
    "    3. <Laptop name>: <Basic laptop specs in brief>, <price of laptop>\n",
    "  {delimiter}\n",
    "\n",
    "  Follow below steps when interacting with user.\n",
    "\n",
    "  Step 1 : Start with a short welcome message and encourage the user to share their requirement precisely on the laptop needed.\n",
    "  Remember, you only recommend on laptop, if user is asking anything else then you apologizes and remind user that you are laptop expert only. Please do not ask more than one questions at a time.\n",
    "\n",
    "  Step 2 : Based on the user input obtained from conversation, you try to get values for 'GPU intensity','Display quality','Portability','Multitasking','Processing speed'and'Budget'.\n",
    "\n",
    "  Step 3 : In case, details are not clear , ask clarifying question to user to get the details for above parameters.\n",
    "\n",
    "  Step 4 : When all the parameters are available you invoke function calling with compare_laptops_with_user function.\n",
    "\n",
    "  Step 5 : Personalize the recommendation obtained from compare_laptops_with_user function and present to the user.\n",
    "\n",
    "  Step 6 : If user changes any of the request then repeat step 2 to 5.\n",
    "\n",
    "\n",
    "  {delimiter}\n",
    "  Here are some notes which you should take care of. If you do not folow this you will be heavily penalized.\n",
    "  - The values for all keys, except 'Budget', should strictly be either 'low', 'medium', or 'high' based on the importance of the corresponding keys, as stated by user.\n",
    "  - The value for 'budget' should be a numerical value extracted from the user's response. It needs to be greater than or equal to 25000 INR.\n",
    "  - Do not ask questions to user for more 1 parameter at a time.\n",
    "  - Do not ask too many questions in one shot.\n",
    "  - Do not reply on any other subject other than laptop and its parameters.\n",
    "\n",
    "\n",
    "    {delimiter}\n",
    "  Her is a sample conversation between user and AI assistant:\n",
    "  User : 'Hi, I am an editor.'\n",
    "  Assistant : 'Great! As an editor, you likely require a laptop tha can handle demanding tasks. hence , the laptop should have high multitasking capability. You would also need a high end display for better visuals and editing. May I know what kind of work do you primarily focus on ? Are you more involved in video editing , photo editing or both ? Understanding the specific type of editing work will help me to tailor my recommendation accordingly. Let me know if my understanding is correct until now.  '\n",
    "  User : ' I primarily work with after effects. '\n",
    "  Assistant : ' Thank you for providing that information. Working with after effects involves working with graphics, animations and rendering which will require high GPU. Do you work with high resolution media files, such as 4K videos or RAW photos ? Understanding your file sizes will help determine the stoprage capacity and processing power needed. '\n",
    "  User : ' Yes, sometimes I work with 4K videos as well. '\n",
    "  Assistant : ' Thank you for the information. Processing 4K videos will require a good and high GPU. I think we have already determined earlier that you need a high CPU. To ensure that I have a complete understanding of your needs, I have one more question : Are you frequently on the go and require a laptop that s light weight and easy to carry, or do you primarily work from a stationary location ?  '\n",
    "  User : ' Yes, sometimes I travel but do not carry my laptop. '\n",
    "  Assistant : ' Could you kindly let me know your budget for the laptop ? This will help me to find the options that fit within your price range while meeting the specified requirements. '\n",
    "  User : ' My maximum budget is 1.5 lakh INR. '\n",
    "\n",
    "  {delimiter}\n",
    "\n",
    "  {delimiter}\n",
    "  Here is another sample conversation between the user and assistant:\n",
    "  User: \"I am a coder and i need higher end laptop with high multitasking feature\"\n",
    "  Assistant: \"Great! As a coder, you likely require a laptop that can handle demanding tasks. Hence, the laptop should have high multitasking capability. Could you please specify the importance of GPU intensity, display quality, portability, processing speed, and budget in order to tailor my recommendation accordingly?\"\n",
    "  User: \"Yes, you are right\"\n",
    "  Assistant: \"Great! Do you prefer a laptop that is easy to carry around or do you primarily use it at a fixed location?\"\n",
    "  User: \"I only need it for home use.\"\n",
    "  Assistant: \"Thank you for specifying that. Do you often have multiple tasks running on your laptop simultaneously or primarily focus on one task at a time?\"\n",
    "  User: \"I ususally have multiple tasks running\"\n",
    "  Assistant: \"Thank you for sharing that. Do you prefer a laptop with fast processing speed for quick performance?\"\n",
    "  User: \"yes i need it to be very quick\"\n",
    "  Assistant: \"Appreciate that input. Finally, what is your budget range for the laptop you are looking to purchase?\"\n",
    "  User: \"i would like if it is not more than 125000 INR\"\n",
    "\n",
    "\n",
    "  {delimiter}\n",
    "  Here is another sample conversation between the user and assistant:\n",
    "  User: \"I am a basic business user\"\n",
    "  Assistant: \"As a basic business user, it's important to have a reliable laptop for your day-to-day tasks. Based on your usage as a basic business user, do you prefer a laptop with a good quality display for presentations?\"\n",
    "  User: \"Yes, you right\"\n",
    "  Assistant: \"Great! Do you prefer a laptop that is easy to carry around or do you primarily use it at a fixed location?\"\n",
    "  User: \"I need it to be easy to carry around as I travel frequently on business trips\"\n",
    "  Assistant: \"Thank you for specifying that. Do you often have multiple tasks running on your laptop simultaneously or primarily focus on one task at a time?\"\n",
    "  User: \"i ususally have multiple tasks running\"\n",
    "  Assistant: \"Thank you for sharing that. Do you prefer a laptop with fast processing speed for quick performance?\"\n",
    "  User: \"yes i need it to be very quick\"\n",
    "  Assistant: \"Appreciate that input. Finally, what is your budget range for the laptop you are looking to purchase?\"\n",
    "  User: \"i would like if it is not more than 1 lakh\"\n",
    "\n",
    "\n",
    "  '''\n",
    "\n",
    "  conversation = [{'role' : 'system' , 'content' : system_message}]\n",
    "\n",
    "  return conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f77346",
   "metadata": {
    "id": "00f77346"
   },
   "source": [
    "Let's now look at the next function.\n",
    "- `get_chat_completions()`: This takes the ongoing conversation as the input and returns the response by the assistant. We'll use the Chat Completions function for performing LLM calls to OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ucpdMHI5_jEX",
   "metadata": {
    "id": "ucpdMHI5_jEX"
   },
   "source": [
    "### `get_chat_completions()`:\n",
    "\n",
    "This function perform LLM call using the Chat Completions API to get the LLM response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dYShGKumNEIM",
   "metadata": {
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1730458071646,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "dYShGKumNEIM"
   },
   "outputs": [],
   "source": [
    "# Define a Chat Completions API call\n",
    "# Retry up to 6 times with exponential backoff, starting at 1 second and maxing out at 20 seconds delay\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def get_chat_completions(input, json_format = False):\n",
    "\n",
    "    MODEL = 'gpt-4o-mini'\n",
    "\n",
    "    system_message_json_output = \"\"\"<<. Return output in JSON format to the key output.>>\"\"\"\n",
    "\n",
    "\n",
    "    try:\n",
    "      # If the output is required to be in JSON format\n",
    "      if json_format == True:\n",
    "          # Append the input prompt to include JSON response as specified by OpenAI\n",
    "          messages = input + system_message_json_output\n",
    "\n",
    "          # JSON return type specified\n",
    "          chat_completion_json = openai.chat.completions.create(\n",
    "              model = MODEL,\n",
    "              messages = messages,\n",
    "              response_format = { \"type\": \"json_object\"},\n",
    "              seed = 1234)\n",
    "\n",
    "          output = json.loads(chat_completion_json.choices[0].message.content)\n",
    "\n",
    "      # No JSON return type specified\n",
    "      else:\n",
    "          message = input\n",
    "          chat_completion = openai.chat.completions.create(\n",
    "              model = MODEL,\n",
    "              messages = input,\n",
    "              seed = 2345)\n",
    "\n",
    "          output = chat_completion.choices[0].message.content\n",
    "      return output\n",
    "\n",
    "    # Handling exception\n",
    "    except Exception as e:\n",
    "      print(f\"An error occurred while calling OpenAI API :  {e}\")\n",
    "      return \"None\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc13511",
   "metadata": {
    "id": "5cc13511"
   },
   "source": [
    "### `moderation_check()`:\n",
    " This checks if the user's or the assistant's message is inappropriate. If any of these is inappropriate, you can add a break statement to end the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c799b4",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730458073823,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "e5c799b4"
   },
   "outputs": [],
   "source": [
    "# Define a function called moderation_check that takes user_input as a parameter.\n",
    "\n",
    "def moderation_check(user_input):\n",
    "    # Call the OpenAI API to perform moderation on the user's input.\n",
    "    response = openai.moderations.create(input=user_input)\n",
    "\n",
    "    # Extract the moderation result from the API response.\n",
    "    moderation_output = response.results[0].flagged\n",
    "    # Check if the input was flagged by the moderation system.\n",
    "    if response.results[0].flagged == True:\n",
    "        # If flagged, return \"Flagged\"\n",
    "        return \"Flagged\"\n",
    "    else:\n",
    "        # If not flagged, return \"Not Flagged\"\n",
    "        return \"Not Flagged\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TWY1b2OXRx4u",
   "metadata": {
    "id": "TWY1b2OXRx4u"
   },
   "source": [
    "## Stage 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ced9d",
   "metadata": {
    "id": "af7ced9d"
   },
   "source": [
    "### 3.3 Implementing the Product Mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R2F8yCDkvsVd",
   "metadata": {
    "id": "R2F8yCDkvsVd"
   },
   "source": [
    "### `product_map_layer()`:\n",
    "\n",
    "This function is responsible for extracting key features and criteria from laptop descriptions. Here's a breakdown of how it works:\n",
    "\n",
    "-  Use a prompt that assign it the role of a Laptop Specifications Classifier, whose objective is to extract key features and classify them based on laptop descriptions.\n",
    "\n",
    "- Provide step-by-step instructions for extracting laptop features from description.\n",
    "\n",
    "- Assign specific rules for each feature (e.g., GPU Intensity, Display Quality, Portability, Multitasking, Processing Speed) and associate them with the appropriate classification value (Low, Medium, or High).\n",
    "\n",
    "- Includes Few Shot Prompting (sample conversation between the user and assistant) to demonstrate the expected result of the feature extraction and classification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "240d34cc",
   "metadata": {
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1730458083031,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "240d34cc"
   },
   "outputs": [],
   "source": [
    "def product_map_layer(laptop_description):\n",
    "    delimiter = \"#####\"\n",
    "\n",
    "    lap_spec = {\n",
    "        \"GPU intensity\":\"(Type of the Graphics Processor)\",\n",
    "        \"Display quality\":\"(Display Type, Screen Resolution, Display Size)\",\n",
    "        \"Portability\":\"(Laptop Weight)\",\n",
    "        \"Multitasking\":\"(RAM Size)\",\n",
    "        \"Processing speed\":\"(CPU Type, Core, Clock Speed)\"\n",
    "    }\n",
    "\n",
    "    values = {'low','medium','high'}\n",
    "\n",
    "    prompt=f\"\"\"\n",
    "    You are a Laptop Specifications Classifier whose job is to extract the key features of laptops and classify them as per their requirements.\n",
    "    To analyze each laptop, perform the following steps:\n",
    "    Step 1: Extract the laptop's primary features from the description {laptop_description}\n",
    "    Step 2: Store the extracted features in {lap_spec} \\\n",
    "    Step 3: Classify each of the items in {lap_spec} into {values} based on the following rules: \\\n",
    "    {delimiter}\n",
    "    GPU Intensity:\n",
    "    - low: <<< if GPU is entry-level such as an integrated graphics processor or entry-level dedicated graphics like Intel UHD >>> , \\n\n",
    "    - medium: <<< if mid-range dedicated graphics like M1, AMD Radeon, Intel Iris >>> , \\n\n",
    "    - high: <<< high-end dedicated graphics like Nvidia RTX >>> , \\n\n",
    "\n",
    "    Display Quality:\n",
    "    - low: <<< if resolution is below Full HD (e.g., 1366x768). >>> , \\n\n",
    "    - medium: <<< if Full HD resolution (1920x1080) or higher. >>> , \\n\n",
    "    - high: <<< if High-resolution display (e.g., 4K, Retina) with excellent color accuracy and features like HDR support. >>> \\n\n",
    "\n",
    "    Portability:\n",
    "    - high: <<< if laptop weight is less than 1.51 kg >>> , \\n\n",
    "    - medium: <<< if laptop weight is between 1.51 kg and 2.51 kg >>> , \\n\n",
    "    - low: <<< if laptop weight is greater than 2.51 kg >>> \\n\n",
    "\n",
    "    Multitasking:\n",
    "    - low: <<< If RAM size is 8 GB, 12 GB >>> , \\n\n",
    "    - medium: <<< if RAM size is 16 GB >>> , \\n\n",
    "    - high: <<< if RAM size is 32 GB, 64 GB >>> \\n\n",
    "\n",
    "    Processing Speed:\n",
    "    - low: <<< if entry-level processors like Intel Core i3, AMD Ryzen 3 >>> , \\n\n",
    "    - medium: <<< if Mid-range processors like Intel Core i5, AMD Ryzen 5 >>> , \\n\n",
    "    - high: <<< if High-performance processors like Intel Core i7, AMD Ryzen 7 or higher >>> \\n\n",
    "    {delimiter}\n",
    "\n",
    "    {delimiter}\n",
    "    Here is input output pair for few-shot learning:\n",
    "    input 1: \"The Dell Inspiron is a versatile laptop that combines powerful performance and affordability. It features an Intel Core i5 processor clocked at 2.4 GHz, ensuring smooth multitasking and efficient computing. With 8GB of RAM and an SSD, it offers quick data access and ample storage capacity. The laptop sports a vibrant 15.6\" LCD display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing experience. Weighing just 2.5 kg, it is highly portable, making it ideal for on-the-go usage. Additionally, it boasts an Intel UHD GPU for decent graphical performance and a backlit keyboard for enhanced typing convenience. With a one-year warranty and a battery life of up to 6 hours, the Dell Inspiron is a reliable companion for work or entertainment. All these features are packed at an affordable price of 35,000, making it an excellent choice for budget-conscious users.\"\n",
    "    output 1: {{'GPU intensity': 'medium','Display quality':'medium','Portability':'medium','Multitasking':'high','Processing speed':'medium'}}\n",
    "\n",
    "    {delimiter}\n",
    "    ### Strictly don't keep any other text in the values of the JSON dictionary other than low or medium or high ###\n",
    "    \"\"\"\n",
    "    input = f\"\"\"Follow the above instructions step-by-step and output the dictionary in JSON format {lap_spec} for the following laptop {laptop_description}.\"\"\"\n",
    "    #see that we are using the Completion endpoint and not the Chatcompletion endpoint\n",
    "    messages=[{\"role\": \"system\", \"content\":prompt },{\"role\": \"user\",\"content\":input}]\n",
    "\n",
    "    response = get_chat_completions(messages, json_format = True)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dG5wTcerDVaH",
   "metadata": {
    "id": "dG5wTcerDVaH"
   },
   "source": [
    "Let's now apply this function to the entire laptop dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9bd0233",
   "metadata": {
    "executionInfo": {
     "elapsed": 26335,
     "status": "ok",
     "timestamp": 1730447312393,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "c9bd0233",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Run this code once to extract product info in the form of a dictionary\n",
    "laptop_df= pd.read_csv(filepath + 'laptop_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nrF2wdgxtWgq",
   "metadata": {
    "id": "nrF2wdgxtWgq"
   },
   "outputs": [],
   "source": [
    "## Create a new column \"laptop_feature\" that contains the dictionary of the product features\n",
    "laptop_df['laptop_feature'] = laptop_df['Description'].apply(lambda x: product_map_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7441d1aa",
   "metadata": {
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1730447371397,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "7441d1aa"
   },
   "outputs": [],
   "source": [
    "## Save this updated csv file so that it can used next time and we do not need to perform this again until we have new details.\n",
    "laptop_df.to_csv(\"laptop_dataset_with_features.csv\",index=False,header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141b150",
   "metadata": {
    "id": "3141b150"
   },
   "source": [
    "### `compare_laptops_with_user()`:\n",
    "\n",
    "This function compares the user's profile with the different laptops and come back with the top  recommendations. It will perform the following steps:\n",
    "    - It will take the user requirements dictionary as input\n",
    "\n",
    "    - Filter the laptops based on their price, keeping only the ones within the user's budget.\n",
    "\n",
    "    - Calculate a score for each laptop based on how well it matches the user's requirements.\n",
    "\n",
    "    - Sort the laptops based on their scores in descending order.\n",
    "    \n",
    "    - Return the top 3 laptops as a JSON-formatted string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "W2-RBmsz2mi_",
   "metadata": {
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1730469681641,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "W2-RBmsz2mi_"
   },
   "outputs": [],
   "source": [
    "def compare_laptops_with_user(user_req_string):\n",
    "\n",
    "  # reading updated input data for laptop details which has features details\n",
    "  df = pd.read_csv(filepath + 'laptop_dataset_with_features.csv')\n",
    "  user_requirements = user_req_string\n",
    "\n",
    "  # extract budget value from user requirement and convert into integer\n",
    "  budget = user_requirements.get('Budget',0)\n",
    "\n",
    "  # create a copy of dataframe after filtering on the budget\n",
    "  df_filtered = df.copy()\n",
    "  df_filtered['Price'] =  df_filtered['Price'].str.replace(',','').astype(int)\n",
    "  df_filtered = df_filtered[df_filtered['Price'] <= budget]\n",
    "\n",
    "  # Mapping string value low medium and high to 0,1 and 2 respectively\n",
    "  mappings = {'low' : 0 , 'medium' : 1 , 'high' : 2}\n",
    "\n",
    "  # creating a new column score and initializing it to 0\n",
    "  df_filtered['Score'] = 0\n",
    "\n",
    "  # now for each laptop, calculate the score based on the input requirement\n",
    "  for index,row in df_filtered.iterrows():\n",
    "    laptop_values = ast.literal_eval(row['laptop_feature'])\n",
    "    score = 0\n",
    "\n",
    "    # now comparing the keys in the laptop values and user requirement\n",
    "    for key,user_value in user_requirements.items():\n",
    "      if key == 'Budget':\n",
    "        continue # skip the comparision\n",
    "      laptop_value = laptop_values.get(key,None)\n",
    "\n",
    "      # checking in mapping\n",
    "      laptop_mapping = mappings.get(laptop_value,-1)\n",
    "      user_mapping   = mappings.get(user_value,-1)\n",
    "\n",
    "      if laptop_mapping >= user_mapping:\n",
    "        score += 1\n",
    "\n",
    "    df_filtered.loc[index,'Score'] = score # updating the score to dataframe\n",
    "\n",
    "  # sorting laptops by score in descending order and selecting 3 products\n",
    "  top_laptops = df_filtered.drop('laptop_feature', axis = 1)\n",
    "  top_laptops = top_laptops.sort_values('Score',ascending=False).head(3)\n",
    "\n",
    "  # converting the top_laptops dataframe to json format\n",
    "  top_laptops_json = top_laptops.to_json(orient='records')\n",
    "\n",
    "  return top_laptops_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kRBzXIcrea7Y",
   "metadata": {
    "id": "kRBzXIcrea7Y"
   },
   "source": [
    "## Stage 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e2eb10",
   "metadata": {
    "id": "f0e2eb10"
   },
   "source": [
    "### 3.4: Product Recommendation Layer\n",
    "\n",
    "Finally, we come to the product recommendation layer. It takes the output from the `compare_laptops_with_user` function in the previous layer and provides the recommendations to the user. It has the following steps.\n",
    "1. It continues the conversation for recommendation.\n",
    "2. Generate the recommendations and display in a presentable format.\n",
    "3. Ask questions basis the recommendations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6270ac40",
   "metadata": {
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1730469879229,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "6270ac40"
   },
   "outputs": [],
   "source": [
    "def get_chat_completions_function_calling(input):\n",
    "\n",
    "    model = 'gpt-4o-mini'\n",
    "\n",
    "    # defining the function call parameters\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"compare_laptops_with_user\",\n",
    "                \"description\": \"Get the top 3 laptops for the user from the catalogue available based on parameters like GPU intensity, Display quality, Portability, Multitasking, Processing speed, and Budget\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"GPU intensity\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The GPU intensity requirement of the user specified as low, medium or high\"\n",
    "                        },\n",
    "                        \"Display quality\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The Display Quality requirement of the user specified as low, medium or high\"\n",
    "                        },\n",
    "                        \"Portability\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The Portability requirement of the user specified as low, medium or high\"\n",
    "                        },\n",
    "                        \"Multitasking\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The Multitasking requirement of the user specified as low, medium or high\"\n",
    "                        },\n",
    "                        \"Processing speed\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The Processing speed requirement of the user specified as low, medium or high\"\n",
    "                        },\n",
    "                        \"Budget\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The maximum budget of the user\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        \"GPU intensity\",\n",
    "                        \"Display quality\",\n",
    "                        \"Portability\",\n",
    "                        \"Multitasking\",\n",
    "                        \"Processing speed\",\n",
    "                        \"Budget\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    try:\n",
    "        messages = input\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model = model,\n",
    "            messages = messages,\n",
    "            temperature = 0,\n",
    "            tools = tools,\n",
    "            tool_choice = 'auto',\n",
    "            seed = 4567\n",
    "        )\n",
    "\n",
    "        # check if the model wanted to call a function\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "        # call the function\n",
    "        if tool_calls:\n",
    "            available_functions = {\n",
    "                \"compare_laptops_with_user\": compare_laptops_with_user,\n",
    "            }\n",
    "\n",
    "            # append response given by gpt to input messages list\n",
    "            messages.append(response.choices[0].message)\n",
    "\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_to_call = available_functions[function_name]\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                function_response = function_to_call(function_args)\n",
    "\n",
    "                function_call_response_dict = {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "\n",
    "                # append response_messages to the original input messages\n",
    "                messages.append(function_call_response_dict)\n",
    "\n",
    "                # make a second call to the LLM to personalize the function output\n",
    "                second_response = openai.chat.completions.create(\n",
    "                    model = model,\n",
    "                    messages = messages,\n",
    "                    temperature = 0 ,\n",
    "                    seed = 5678\n",
    "\n",
    "                )\n",
    "\n",
    "                second_response_message = [{\"role\": \"assistant\", \"content\": second_response.choices[0].message.content}]\n",
    "                return second_response_message\n",
    "        else:\n",
    "            response_message = [{\"role\": \"assistant\", \"content\": response.choices[0].message.content}]\n",
    "            return response_message\n",
    "\n",
    "    # Raise exception error\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Djt_gMeaeo-F",
   "metadata": {
    "id": "Djt_gMeaeo-F"
   },
   "source": [
    "## Combining all the 3 stages\n",
    "\n",
    "Now, we combine all the three stages that we defined above.\n",
    "\n",
    "`Stage 1` + `Stage 2` + `Stage 3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156fc35",
   "metadata": {
    "id": "8156fc35"
   },
   "source": [
    "### 3.5 Dialogue Management System\n",
    "\n",
    "Bringing everything together, we create a `diagloue_mgmt_system()` function that contains the logic of how the different layers would interact with each other. This will be the function that we'll call to initiate the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "SQTdraD3qwZY",
   "metadata": {
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1730460735475,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "SQTdraD3qwZY"
   },
   "outputs": [],
   "source": [
    "def dialogue_mgmt_system():\n",
    "    # initialize the conversation\n",
    "    conversation = initialize_conversation()\n",
    "    # First message from Assistant\n",
    "    print(\"Assistant:\\nHow may I help you with your laptop selection?\\n\")\n",
    "\n",
    "    user_input = ''\n",
    "\n",
    "    # Loop till user exits\n",
    "    while user_input.lower() != 'exit':\n",
    "        print(\"User: \")\n",
    "        user_input = input()\n",
    "        # Moderation Check for user input\n",
    "        moderation = moderation_check(user_input)\n",
    "        if moderation == 'Flagged':\n",
    "            print(\"\\nAssistant:\\nSorry, this message has been flagged. Please restart your conversation.\\n\")\n",
    "            break\n",
    "\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"\\nAssistant:\\nThank you for using this service. Please do not hesitate to contact us if you need assistance. See you soon!\\n\")\n",
    "            break\n",
    "\n",
    "        conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "        response = get_chat_completions_function_calling(conversation)\n",
    "\n",
    "        # Moderation Check for LLM response\n",
    "        moderation = moderation_check(response[0]['content'])\n",
    "        if moderation == 'Flagged':\n",
    "            print(\"\\nAssistant:\\nSorry, this message has been flagged. Please restart your conversation.\\n\")\n",
    "            break\n",
    "\n",
    "        print(\"\\nAssistant:\\n\", response[0]['content'], '\\n')\n",
    "\n",
    "        conversation += response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "WdXuDd2cV3lN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154674,
     "status": "ok",
     "timestamp": 1730470054840,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "WdXuDd2cV3lN",
    "outputId": "5ccf656c-6d68-4912-bced-9933ad2f9e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:\n",
      "How may I help you with your laptop selection?\n",
      "\n",
      "User: \n",
      "I am a gamer\n",
      "\n",
      "Assistant:\n",
      " Great! As a gamer, you'll likely need a laptop with a strong GPU for high-quality graphics, good processing speed for smooth gameplay, and possibly high multitasking capabilities if you run multiple applications. \n",
      "\n",
      "To better understand your needs, could you please tell me how important GPU intensity is for you? Would you say it's high, medium, or low? \n",
      "\n",
      "User: \n",
      "high speed and higer praphics \n",
      "\n",
      "Assistant:\n",
      " Thank you for that information! It sounds like you need a laptop with high GPU intensity and high processing speed. \n",
      "\n",
      "Next, how important is display quality for your gaming experience? Would you rate it as high, medium, or low? \n",
      "\n",
      "User: \n",
      "medium \n",
      "\n",
      "Assistant:\n",
      " Got it! So, you need high GPU intensity, high processing speed, and medium display quality. \n",
      "\n",
      "Now, how important is portability for you? Do you prefer a laptop that is easy to carry around, or do you primarily use it at a fixed location? Please rate it as high, medium, or low. \n",
      "\n",
      "User: \n",
      "I use only at home \n",
      "\n",
      "Assistant:\n",
      " Thank you for clarifying! Since you primarily use the laptop at home, I will consider portability as low.\n",
      "\n",
      "Next, do you often have multiple tasks running on your laptop simultaneously while gaming, or do you primarily focus on one task at a time? Please rate multitasking as high, medium, or low. \n",
      "\n",
      "User: \n",
      "medium \n",
      "\n",
      "Assistant:\n",
      " Great! So we have the following parameters so far:\n",
      "\n",
      "- GPU intensity: high\n",
      "- Display quality: medium\n",
      "- Portability: low\n",
      "- Multitasking: medium\n",
      "\n",
      "Finally, could you please let me know your budget for the laptop? This will help me find options that fit within your price range. \n",
      "\n",
      "User: \n",
      "1050 USD\n",
      "\n",
      "Assistant:\n",
      " Here are the top 3 laptop recommendations based on your gaming requirements:\n",
      "\n",
      "1. **MSI GL65**: Powered by an Intel Core i7 processor (2.6 GHz), 16GB RAM, and a combination of HDD and SSD storage. It features a 15.6\" IPS display with a resolution of 1920x1080 and an NVIDIA GTX graphics card for excellent visual performance. Weighing 2.3 kg, it has an RGB keyboard and a battery life of up to 4 hours. Price: **55,000 INR**.\n",
      "\n",
      "2. **Acer Predator**: Equipped with an Intel Core i7 processor (2.8 GHz), 16GB RAM, and SSD storage. It has a large 17.3\" IPS display with a resolution of 1920x1080 and an NVIDIA GTX graphics card. Weighing 3.2 kg, it features dual cooling fans and a battery life of up to 5 hours. Price: **80,000 INR**.\n",
      "\n",
      "3. **Lenovo ThinkPad**: Features an AMD Ryzen 7 processor (3.0 GHz), 16GB RAM, and SSD storage. It has a 14\" IPS display with a resolution of 2560x1440 and an NVIDIA GTX graphics card. Weighing just 1.6 kg, it includes a backlit keyboard and a battery life of up to 6 hours. Price: **60,000 INR**.\n",
      "\n",
      "These laptops should meet your gaming needs effectively! If you have any further questions or need more options, feel free to ask. \n",
      "\n",
      "User: \n",
      "exit\n",
      "\n",
      "Assistant:\n",
      "Thank you for using this service. Please do not hesitate to contact us if you need assistance. See you soon!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogue_mgmt_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7mZHQutBed40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101540,
     "status": "ok",
     "timestamp": 1730470187325,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "7mZHQutBed40",
    "outputId": "51dd9ab2-0fa3-4916-a5d9-b7d6d4b8fc51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:\n",
      "How may I help you with your laptop selection?\n",
      "\n",
      "User: \n",
      "I am a student \n",
      "\n",
      "Assistant:\n",
      " Welcome! As a student, it's important to have a laptop that meets your academic needs. Could you please share what specific tasks you'll be using the laptop for? For example, will you be doing programming, graphic design, writing papers, or something else? This will help me tailor my recommendations for you. \n",
      "\n",
      "User: \n",
      "I need it for my basic assignment needs with medium specifications\n",
      "\n",
      "Assistant:\n",
      " Thank you for sharing that! For basic assignments, it's good to have a reliable laptop. Could you please let me know how important the following factors are for you: GPU intensity, display quality, portability, multitasking, and processing speed? You can rate them as high, medium, or low based on your preferences. \n",
      "\n",
      "User: \n",
      "All with medium specifications\n",
      "\n",
      "Assistant:\n",
      " Got it! So you need medium specifications for GPU intensity, display quality, portability, multitasking, and processing speed. \n",
      "\n",
      "Now, could you please let me know your budget for the laptop? This will help me find options that fit within your price range. \n",
      "\n",
      "User: \n",
      "60000 INR\n",
      "\n",
      "Assistant:\n",
      " Here are the top 3 laptop recommendations based on your requirements:\n",
      "\n",
      "1. **Dell Inspiron**: Intel Core i5, 8GB RAM, 15.6\" LCD display (1920x1080), Intel UHD graphics, SSD storage, weighs 2.5 kg, average battery life of 6 hours, priced at 35,000 INR. This laptop is versatile and affordable, making it an excellent choice for basic assignments.\n",
      "\n",
      "2. **MSI GL65**: Intel Core i7, 16GB RAM, 15.6\" IPS display (1920x1080), NVIDIA GTX graphics, HDD+SSD storage, weighs 2.3 kg, average battery life of 4 hours, priced at 55,000 INR. This high-performance laptop is designed for gaming but also handles demanding tasks well.\n",
      "\n",
      "3. **Lenovo ThinkPad**: AMD Ryzen 7, 16GB RAM, 14\" IPS display (2560x1440), NVIDIA GTX graphics, SSD storage, weighs 1.6 kg, average battery life of 6 hours, priced at 60,000 INR. This powerful laptop is ideal for professional users and offers a versatile display.\n",
      "\n",
      "Let me know if you need any more information or if you would like to explore other options! \n",
      "\n",
      "User: \n",
      "exit\n",
      "\n",
      "Assistant:\n",
      "Thank you for using this service. Please do not hesitate to contact us if you need assistance. See you soon!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogue_mgmt_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "GJ8_aNd_DgGA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9741,
     "status": "ok",
     "timestamp": 1730470204213,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "GJ8_aNd_DgGA",
    "outputId": "a24e835f-ca71-4be5-d44b-e3d3357806f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:\n",
      "How may I help you with your laptop selection?\n",
      "\n",
      "User: \n",
      "I will kill someone\n",
      "\n",
      "Assistant:\n",
      "Sorry, this message has been flagged. Please restart your conversation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogue_mgmt_system()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "zOek-6GdD6o6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27211,
     "status": "ok",
     "timestamp": 1730470239809,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "zOek-6GdD6o6",
    "outputId": "9ac6bc84-49e8-4484-85db-0b553ee5d14f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:\n",
      "How may I help you with your laptop selection?\n",
      "\n",
      "User: \n",
      "Can you please prescribe some book\n",
      "\n",
      "Assistant:\n",
      " I'm sorry, but I'm a laptop expert and can only assist you with laptop-related queries. If you have any specific requirements for a laptop, feel free to share! \n",
      "\n",
      "User: \n",
      "exit\n",
      "\n",
      "Assistant:\n",
      "Thank you for using this service. Please do not hesitate to contact us if you need assistance. See you soon!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogue_mgmt_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfYQ558kD_BB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15687,
     "status": "ok",
     "timestamp": 1730470263978,
     "user": {
      "displayName": "Dipak Sah",
      "userId": "03831944781254646591"
     },
     "user_tz": -330
    },
    "id": "dfYQ558kD_BB",
    "outputId": "121050e3-842a-489f-e2ff-dc33929a3b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:\n",
      "How may I help you with your laptop selection?\n",
      "\n",
      "User: \n",
      "plan a trip for london \n",
      "\n",
      "Assistant:\n",
      " I'm sorry, but I'm a laptop expert and can only assist you with laptop-related queries. If you have any questions about laptops or need help finding the right one for your needs, feel free to ask! \n",
      "\n",
      "User: \n",
      "exit\n",
      "\n",
      "Assistant:\n",
      "Thank you for using this service. Please do not hesitate to contact us if you need assistance. See you soon!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogue_mgmt_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84YpDnupEHxL",
   "metadata": {
    "id": "84YpDnupEHxL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
